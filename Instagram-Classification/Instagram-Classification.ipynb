{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applied Data Analysis project\n",
    "\n",
    "## Instagram Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The role of this notebook is to walk you through the whole process of Instagram Sentiment Classification part of the project in a way that will allow you to easily reproduce the results yourself.     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal formulation\n",
    "In this part of the project our goal was to detect sentiment in the Instagram images and images only, i.e we have disregarded all textual description of the image. This was done to reduce our task to an image classification problem. \n",
    "\n",
    "The name \"Sentiment analysis\" might be a bit misleading here. We do not want the sentiment per se, as in happy versus sad face occurring in the image. Instead, we consider an image to have a positive sentiment if it depicts place that it is pleasant to walk through or by. \n",
    "\n",
    "The original plan was to do something in style of [goodcitylife.org](http://www.goodcitylife.org/), i.e. classifying a sentiment of particular streets in some swiss city. However, our data does not contain location information with such a level of granularity. Therefore, we have redefined our goal to be sentiment (or pleasantness) analysis of cities in Switzerland instead of streets in one specific swiss city."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General approach definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we have planned to train a new convolutional network using data from [image-net.org](http://image-net.org/). Image-net.org contains extensive amount of images divided into categories by the object that is depicted in them. We have wanted to download several categories, positive (e.g. mountains, lakeside), neutral (faces, dogs, food) and negative (graffiti, thrash) and train the network on them. However, we have realized that this would have taken too much time to train. \n",
    "\n",
    "After some research, we have found out about [Inception v3](https://arxiv.org/abs/1512.00567) - a convolutional neural network model pre-trained on all 1000 image categories of image-net. We have tested it on sample of our data and, as it performed quite well, we have decided to include it in our pipeline.\n",
    "\n",
    "![Inception v3 Architecture](inception_v3.png)\n",
    "<span style=\"width:100%;text-align:center;float:right;\"><i>Schematic diagram of Inception-v3 (source: https://codelabs.developers.google.com/codelabs/cpb102-txf-learning/)</i></span><br>\n",
    "\n",
    "\n",
    "Inception v3 model returns labels of N most probable objects depicted in the image together with confidence of the classification. We have desided to leverage this and use these labels and confidences to calculate the sentiment. An example of an image from our dataset as an input and Inception v3 output on that image follow:  \n",
    "<img src=\"https://scontent.cdninstagram.com/t51.2885-15/e35/14063668_297414773969254_2078795989_n.jpg?ig_cache_key=MTMyOTc0Mzk5ODMxOTA1MjE3MA%3D%3D.2\" alt=\"Sample Instagram Image\" style=\"width: 300px; margin-right: 10px;\" align=\"left\"/>\n",
    "<br>\n",
    "{  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"alp\": 0.016730202361941338,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"dam, dike, dyke\": 0.2930382788181305,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"lakeside, lakeshore\": 0.29257863759994507,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"promontory, headland, head, foreland\": 0.07077361643314362,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"valley, vale\": 0.10409216582775116  \n",
    "}  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Technical discussion\n",
    "Even though we have some experience with [TensorFlow](https://www.tensorflow.org/) library, our original plan has been to use [Keras](https://keras.io/) library for the convolutional neural network, just for the sake of learning something new. However, as we have been quite constrained on time available, in the end we have decided to use only TensorFlow library for implementing the neural network.\n",
    "\n",
    "However, we had problems running TensorFlow on [Spark](http://spark.apache.org/) cluster that we were provided by [EPFL](http://epfl.ch/). Thus, we have resorted to using [Amazon AWS EC2](https://aws.amazon.com/ec2/) servers. \n",
    "\n",
    "We have used [python3.5](https://www.python.org/downloads/release/python-353/) and [bash](https://tiswww.case.edu/php/chet/bash/bashtop.html) in our endeavours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "I will start the explanation of the pipeline from Felix's output in [/Instagram-Download/](https://github.com/korcek-juraj/epfl-ada16-project/tree/master/Instagram-Download) folder. I have received files form Felix where every line contained Instagram Image ID and its url, the two separated by a space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline - 1. Data preprocessing\n",
    "I wanted to load the file into python and, additionally, in our dataset there were more urls for one Instagram Image ID. Therefore, I had to preprocess the file. This is done by [create_url_dict.py](https://github.com/korcek-juraj/epfl-ada16-project/blob/master/Instagram-Classification/create_url_dict.py) script. It results in python dictionary with every Instagram Image ID as key and a list of urls associated to it as value. The result is pickled into the file with the same name, just with .pickle extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ./create_url_dict.py\n",
    "import os\n",
    "import argparse\n",
    "import pickle\n",
    "\n",
    "\n",
    "def create_url_dict(filename, append_to_dict=None):\n",
    "    \"\"\"\n",
    "    Processes the file passed in filename argument.\n",
    "    The file is expected to contain key-value pairs (split by space) of Instagram image ID and its url at every line.\n",
    "\n",
    "    The result is a dictionary with every Instagram Image ID as key and list of urls associated to it as value.\n",
    "\n",
    "    The parsed results can be returned as a new dictionary or be appended to an existing one passed in argument 'append_to_dict'\n",
    "    :param filename: a file with Instagram IDs and urls to process\n",
    "    :param append_to_dict: a dictionary to append the results to; if None, new dictionary is returned\n",
    "    :return: new dictionary or modified dictionary passed in 'append_to_dict' parameter\n",
    "    \"\"\"\n",
    "    if append_to_dict is None:\n",
    "        ret = {}\n",
    "    else:\n",
    "        ret = append_to_dict\n",
    "\n",
    "    with open(filename) as urlfile:\n",
    "        for line in urlfile:\n",
    "            elem_list = line.split()\n",
    "            if elem_list[0] in ret:\n",
    "                ret[elem_list[0]].append(elem_list[1])\n",
    "            else:\n",
    "                ret[elem_list[0]] = [elem_list[1], ]\n",
    "    return ret\n",
    "\n",
    "\n",
    "def main(filename):\n",
    "    \"\"\"\n",
    "    Parses file passed in filename using create_url_dict method and pickles resulting dictionary for further use.\n",
    "\n",
    "    Resulting pickle file is saved into the same directory as the input file with the same filename,\n",
    "    but with extension '.pickle'.\n",
    "    :param filename: filename of file to be parsed\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    filename, ext = os.path.splitext(args.filename)\n",
    "    urldict = create_url_dict(filename + ext)\n",
    "    with open(filename + '.pickle', 'wb') as handle:\n",
    "        pickle.dump(urldict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-f', '--filename', type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    main(args.filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run the script on urls from September to October. Just a note, if you want to run the script from commandline instead of notebook, you need to write `python3 create_url_dict.py -f months/september-october_urls.txt` (assuming you are in directory where the script is located)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ./create_url_dict.py -f months/september-october_urls.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the /Instagram-Classification/months folder you will see that september-october_urls.pickle got created/updated. We will use it in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline - 2. Parallelized Download & Classification\n",
    "In order to leverage the computational power of the Amazon AWS EC2 servers we had to parallelize our computation well. Our pipeline consists of $d$ download workers (processes) that download images from Instagram, $c$ classification workers that classify images using TensorFlow library and Inception v3 model, 1 worker to write the results into a file and 1 worker to report progress. To send jobs/data from one worker type to another we have used process-safe queues from python's [multiprocessing](https://docs.python.org/3.5/library/multiprocessing.html) library. \n",
    "\n",
    "This way, utilizing the computing architecture to the fullest is a matter of setting couple of parameters correctly. It is important to get balance between download and classification processes right. If you have too little download processes, your classification processes will starve because they will not have anything to process, you will not utilize the computational power to the fullest and thus you will waste time. On the other hand, if you have too many download processes, the classification processes might be too slow to process the images and thus they might start accumulating on your storage until you run out of space and the script crashes.\n",
    "\n",
    "The [pipeline.py](https://github.com/korcek-juraj/epfl-ada16-project/blob/master/Instagram-Classification/pipeline.py) script takes care of running this.\n",
    "\n",
    "The images are downloaded into /Instagram-Classification/images/ folder and are removed after they are processed. If some image fails to download, an empty file with name InstagramImageID.jpg.failed is created in the directory. Therefore, it is a good idea to clean the images /Instagram-Classification/images/ folder between the runs.\n",
    "\n",
    "The classification results are written into file specified by `-o` or `--output_json_file parameter`. If it is not specified, the results are written into result%Y%m%d-%H%M%S.json file in /Instagram-Classification/ directory. This file has the .json extension, however it is not valid JSON as a whole. However, it is each line of this file that contains valid JSON string. This was done so that the results can be written one by one into the file without need to keep all the results in memory which would be the case if if we wanted to write valid JSON file. This has also an advantage that results from different runs can be easily merged into one file by using simple shell command: `cat results1.json results2.json results3.json > results_all.json`\n",
    "\n",
    "If you do not want to download and analyse all the Instagram Image IDs in the .pickle file (e.g. when testing/debugging) you can use optional script parameter `-t` or `--test_run` to specifify number of Image IDs to process. Not setting this parmater or setting it to 0 results in processing all the Image IDs in the .pickle file.\n",
    "\n",
    "You can also specify progress reporting interval by setting `-ri` or `--progress_report_interval` to number of seconds you desire. The deafult is 5 seconds. If you set it to 0 no reporting will take place.\n",
    "\n",
    "The script writes logs into stdout. Probably the best way to run the script is to run it on background using `&` and redirecting the output into, e.g., log.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ./pipeline.py\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing import Process, Queue, Value\n",
    "from queue import Empty\n",
    "from urllib import request, error\n",
    "import os.path\n",
    "from ctypes import c_bool\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import errno\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from classify_image import maybe_download_and_extract, create_graph, NodeLookup, FLAGS\n",
    "\n",
    "\n",
    "def download_worker(url_queue, image_queue):\n",
    "    \"\"\"\n",
    "    A worker for download processes.\n",
    "\n",
    "    It executes following steps repeatedly:\n",
    "    1) It gets Instagram Image ID and corresponding list of urls from \"process-safe\" queue passed in url_queue parameter.\n",
    "\n",
    "    2) It attempts to download the image from urls available in the list into images/ folder as InstagramID.jpg file. If\n",
    "    the image is successfully downloaded using an url, the rest of the urls for given Instagram Image ID in the list is\n",
    "    ignored. If none of the urls worked, an empty file with name InstagramID.jpg.failed is created in the images/ directory\n",
    "    for logging purposes.\n",
    "\n",
    "    3) Once the image is downloaded its filename is put into the \"process-safe\" queue passed in image_queue parameter.\n",
    "     From this queue classification workers obtain read-to-be-classified images.\n",
    "\n",
    "    If an exception is thrown, it is logged and the worker continues to process next Instagram Image ID.\n",
    "\n",
    "    The process / worker exits once it gets (None, None) tuple from the url_queue.\n",
    "    :param url_queue: \"process-safe\" queue containing tuples (Instagram Image ID, list of image urls corresponding to given ID)\n",
    "    :param image_queue: \"process-safe\" queue containing image filenames to be processed by classification workers\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            img_id, url_list = url_queue.get(timeout=1)\n",
    "            if img_id is None:\n",
    "                break\n",
    "            filename = 'images/' + img_id + '.jpg'\n",
    "            if os.path.isfile(filename):\n",
    "                image_queue.put(filename)\n",
    "                continue\n",
    "            else:\n",
    "                for url in url_list:\n",
    "                    try:\n",
    "                        request.urlretrieve(url, filename)\n",
    "                        break\n",
    "                    except (error.HTTPError, error.URLError):\n",
    "                        continue\n",
    "                if not os.path.isfile(filename):\n",
    "                    open(filename + '.failed','a+').close()\n",
    "                    print(img_id + ': image missing!', flush=True)\n",
    "                else:\n",
    "                    image_queue.put(filename)\n",
    "        except Empty:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print('Unexpected exception in download_worker: ' + str(e), flush=True)\n",
    "\n",
    "\n",
    "def classification_worker(image_queue, result_queue):\n",
    "    \"\"\"\n",
    "    A worker for classification processes.\n",
    "\n",
    "    First, it loads TensorFlow Inception v3 CNN model using create_graph() function and initializes TensorFlow session.\n",
    "\n",
    "    Then, it executes following steps repeatedly:\n",
    "    1) It gets image filename from \"process-safe\" queue passed in image_queue parameter.\n",
    "\n",
    "    2) It runs predictions on the image using predict() function.\n",
    "\n",
    "    3) It deletes the image.\n",
    "\n",
    "    4) The result is pushed onto \"process-safe\" queue passed in result_queue parameter in form of dictionary {img_id: result}.\n",
    "     This queue feeds the process / worker responsible for saving the results into a file.\n",
    "\n",
    "    If an exception is thrown, it is logged and the worker continues to process next image file.\n",
    "\n",
    "    The process / worker exits once it gets None from the image_queue.\n",
    "    :param image_queue: \"process-safe\" queue containing filenames of images to be classified\n",
    "    :param result_queue: \"process-safe\" queue containing classification results to be processed by results-saving worker\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    create_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        # 'softmax:0': A tensor containing the normalized prediction across\n",
    "        #   1000 labels.\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                image = image_queue.get(timeout=1)\n",
    "                if image is None:\n",
    "                    break\n",
    "                img_id, result = predict(image, sess, softmax_tensor)\n",
    "                result_queue.put({img_id: result})\n",
    "                os.remove(image)\n",
    "            except Empty:\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print('Unexpected exception in classification_worker: ' + str(e), flush=True)\n",
    "\n",
    "\n",
    "def predict(image, sess, softmax_tensor):\n",
    "    \"\"\"\n",
    "    Function used by classification workers to get prediction on image.\n",
    "\n",
    "    This method was adapted based on run_inference_on_image() method from classify_image.py found in TensorFlow official tutorial.\n",
    "\n",
    "    :param image: filename of the image to be classified\n",
    "    :param sess: TensorFlow session\n",
    "    :param softmax_tensor: tensor used for computing the predictions\n",
    "    :return: (img_id, result) with img_id being Instagram Image ID and the result being dictionary with 5 most probable\n",
    "    objects depicted in the image as keys and corresponding prediction confidences as values.\n",
    "    \"\"\"\n",
    "    img_id = os.path.splitext(os.path.basename(image))[0]\n",
    "    image_data = tf.gfile.FastGFile(image, 'rb').read()\n",
    "\n",
    "    # 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "    #   encoding of the image.\n",
    "    predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "    predictions = np.squeeze(predictions)\n",
    "\n",
    "    # Creates node ID --> English string lookup.\n",
    "    node_lookup = NodeLookup()\n",
    "\n",
    "    top_k = predictions.argsort()[-FLAGS.num_top_predictions:][::-1]\n",
    "    result = {}\n",
    "    for node_id in top_k:\n",
    "        human_string = node_lookup.id_to_string(node_id)\n",
    "        score = predictions[node_id]\n",
    "        result[human_string] = float(score)\n",
    "\n",
    "    return img_id, result\n",
    "\n",
    "\n",
    "def save_result_worker(result_queue, output_file):\n",
    "    \"\"\"\n",
    "    A worker for process saving the classification results into a file.\n",
    "\n",
    "    First, it opens/creates the outputfile specified in output_file parameter.\n",
    "\n",
    "    Then, it executes following steps repeatedly:\n",
    "    1) It gets image result dictionary from \"process-safe\" queue passed in result_queue parameter.\n",
    "\n",
    "    2) It converts the result into JSON format and appends it to the output file.\n",
    "\n",
    "    The process / worker exits once it gets None from the result_queue.\n",
    "    :param result_queue: \"process-safe\" queue containing results from image classification in form of one dictionary per image\n",
    "    :param output_file: filename of the results file to be written to\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dir_path = os.path.dirname(output_file)\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(dir_path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    with open(output_file, \"a+\") as result_file:\n",
    "        while True:\n",
    "            try:\n",
    "                kv = result_queue.get(timeout=1)\n",
    "                if kv is None:\n",
    "                    break\n",
    "                result_file.write(json.dumps(kv) + '\\n')\n",
    "            except Empty:\n",
    "                continue\n",
    "\n",
    "\n",
    "def progress_reporting_worker(url_queue, url_queue_orig_len, image_queue, result_queue, progress_report_interval):\n",
    "    \"\"\"\n",
    "    A simple worker for progress reporting and debugging purposes.\n",
    "\n",
    "    It writes into the stdout number of images remaining to be processed.\n",
    "\n",
    "    It also writes size of the two queues. This is useful to decide whether there is balance between number of download\n",
    "    and classification workers.\n",
    "\n",
    "    The process / worker is expected to be run in daemon mode and thus to exit once its parent process exits. Thus the\n",
    "    infinite loops is not a problem.\n",
    "    :param url_queue: \"process-safe\" queue containing tuples (Instagram Image ID, list of image urls corresponding to given ID)\n",
    "    :param url_queue_orig_len: original length of url_queue\n",
    "    :param image_queue: \"process-safe\" queue containing filenames of images to be classified\n",
    "    :param result_queue: \"process-safe\" queue containing results from image classification in form of one dictionary per image\n",
    "    :param progress_report_interval: interval how often to write the current progress into stdout in seconds\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        print('Images remaining (length of url_queue): ' + str(url_queue.qsize()) + '/' + str(url_queue_orig_len), flush=True)\n",
    "        print('image_queue length: ' + str(image_queue.qsize()), flush=True)\n",
    "        print('result_queue length: ' + str(result_queue.qsize()), flush=True)\n",
    "        time.sleep(progress_report_interval)\n",
    "\n",
    "\n",
    "def main(path_to_imgs_pickle, test_run, download_process_no, classification_process_no, output_file, progress_report_interval):\n",
    "    \"\"\"\n",
    "    Sets up and runs the multiprocessing pipeline.\n",
    "\n",
    "    It consists of following steps:\n",
    "    1) Downloading Inception v3 model if it is not present. This is done by maybe_download_and_extract() function.\n",
    "\n",
    "    2) Filling imgid_urls_queue \"process-safe\" queue with Instagram Image IDs and its corresponding url lists from pickle\n",
    "     file passed in path_to_imgs_pickle parameter. The amount of key value pairs (Image ID, url list) loaded is limited\n",
    "     by the parameter test_run. Setting it to 0 or None loads all the available records form the file.\n",
    "\n",
    "    3) Initialization of  \"process-safe\" queues img_filename_queue and result_queue.\n",
    "\n",
    "    4) Spawning number of download process which is specified in download_process_no parameter.\n",
    "    It also download_process_no-times appends tuples (None, None) to the end of imgid_urls_queue to signal the end of\n",
    "    the queue for the download workers.\n",
    "\n",
    "    5) Spawning number of classification process which is specified in classification_process_no parameter.\n",
    "\n",
    "    6) Spawning worker for saving results into a file.\n",
    "\n",
    "    7) Spawning progress-reporting worker.\n",
    "\n",
    "    8) Joining the download workers. Once the download is done None is appened to the end of img_filename_queue\n",
    "    classification_process_no-times to signal classification workers the end of queue.\n",
    "\n",
    "    9) Joining classification workers. Once that is done, None is appended result_queue to signal results-saving worker\n",
    "    the end of queue.\n",
    "\n",
    "    10) Joining the results-saving worker.\n",
    "\n",
    "    The progress reporting worker quits automatically with the main (parent) process because it is of daemon type.\n",
    "    Therefore there is no need to join it.\n",
    "    :param path_to_imgs_pickle: path to pickle file containing dictionary of Instagram Image IDs as keys and corresponding lists of urls as values\n",
    "    :param test_run: amount of Instagram Images IDs to classify; None or 0 if all\n",
    "    :param download_process_no: number of download processes\n",
    "    :param classification_process_no: number of classification processes\n",
    "    :param output_file: filename of the results file to be written to\n",
    "    :param progress_report_interval: interval how often to write the current progress into stdout in seconds; if None or 0 => no progress reporting\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    ctx = multiprocessing.get_context('spawn')\n",
    "\n",
    "    maybe_download_and_extract()\n",
    "\n",
    "    with open(path_to_imgs_pickle, 'rb') as handle:\n",
    "        urldict = pickle.load(handle)\n",
    "\n",
    "    imgid_urls_queue = ctx.Queue()\n",
    "    i = 0\n",
    "    for img_id, url_list in urldict.items():\n",
    "        i += 1\n",
    "        imgid_urls_queue.put((img_id, url_list))\n",
    "        if test_run and i >= test_run:\n",
    "            break\n",
    "    imgid_urls_queue_orig_len = imgid_urls_queue.qsize()\n",
    "\n",
    "    img_filename_queue = ctx.Queue()\n",
    "\n",
    "    download_p_list = []\n",
    "    for i in range(1, download_process_no + 1):\n",
    "        download_p = ctx.Process(target=download_worker, args=(imgid_urls_queue, img_filename_queue,))\n",
    "        download_p_list.append(download_p)\n",
    "        imgid_urls_queue.put((None, None))\n",
    "        download_p.start()\n",
    "\n",
    "    result_queue = ctx.Queue()\n",
    "\n",
    "    classification_p_list = []\n",
    "    for i in range(1, classification_process_no + 1):\n",
    "        classification_p = ctx.Process(target=classification_worker, args=(img_filename_queue, result_queue,))\n",
    "        classification_p_list.append(classification_p)\n",
    "        classification_p.start()\n",
    "\n",
    "    save_results_p = ctx.Process(target=save_result_worker, args=(result_queue, output_file,))\n",
    "    save_results_p.start()\n",
    "\n",
    "    if progress_report_interval:\n",
    "        progress_reporting_p = Process(target=progress_reporting_worker, args=(imgid_urls_queue, imgid_urls_queue_orig_len, img_filename_queue, result_queue, progress_report_interval,))\n",
    "        progress_reporting_p.daemon = True\n",
    "        progress_reporting_p.start()\n",
    "\n",
    "    for p in download_p_list:\n",
    "        p.join()\n",
    "\n",
    "    print('Download done!', flush=True)\n",
    "\n",
    "    for p in classification_p_list:\n",
    "        img_filename_queue.put(None)\n",
    "\n",
    "    for p in classification_p_list:\n",
    "        p.join()\n",
    "\n",
    "    print('Classification done!', flush=True)\n",
    "\n",
    "    result_queue.put(None)\n",
    "\n",
    "    save_results_p.join()\n",
    "\n",
    "    print('Done!')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-p', '--path_to_imgs_pickle', type=str, required=True)\n",
    "    parser.add_argument('-o', '--output_json_file', type=str)\n",
    "    parser.add_argument('-dp', '--download_process_count', type=int, default=2)\n",
    "    parser.add_argument('-cp', '--classification_process_count', type=int, default=3)\n",
    "    parser.add_argument('-t', '--test_run', type=int, default=0, help='amount of images to process, None or 0 if all')\n",
    "    parser.add_argument('-ri', '--progress_report_interval', type=int, default=5, help='in seconds, if None or 0 => no progress reporting')\n",
    "    args = parser.parse_args()\n",
    "    if args.output_json_file:\n",
    "        output_file = args.output_json_file\n",
    "    else:\n",
    "        output_file = 'result' + time.strftime(\"%Y%m%d-%H%M%S\") + '.json'\n",
    "\n",
    "    main(args.path_to_imgs_pickle, args.test_run, args.download_process_count, args.classification_process_count, output_file, args.progress_report_interval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will run the script to download & classify first 100 images from september-october_urls.pickle that we have created in previous step. \n",
    "\n",
    "IMPORTANT: The next cell will probably fail becuase interactive notebooks and multiprocessing are not much of friends (at least on Windows). In that case you will have to run the command from shell calling `python3 pipeline.py -p months/september-october_urls.pickle -t 100 --download_process_count 2 --classification_process_count 4 -o results/september-october_urls_result.json >> log.txt &` (again assuming you are in directory where the script is located). This will run the script on background and thus if you want to see the live updates of log, run `less +F log.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%run ./pipeline.py -p months/september-october_urls.pickle -t 100 --download_process_count 2 --classification_process_count 4 -o results/september-october_urls_result.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the script finishes you should see that result_september-october_urls.json got created. We will use it in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pipeline - 2. Parallelized Download & Classification - Speed considerations\n",
    "\n",
    "We have run the computation on a laptop and on 3 different instances of Amazon AWS EC2. The reason for this was an attempt to get results as fast as possible. However, a nice side efect of this is that we are able to analyse speed improvemnts due to parallelization.\n",
    "\n",
    "  Machine       | CPU cores    | Internet connection | # download workers | # classification workers | # images processed / second\n",
    "  ------------- | -------------\n",
    "  Laptop Dell Latitude E7450 | 4 (threads) | 30 Mbps | 1 | 3 | ~1\n",
    "  c4.8xlarge  | 36 | 10 Gbps | 8 | 24 | ~20\n",
    "  m4.16xlarge | 64 | 20 Gbps | 12 | 50| ~25\n",
    "\n",
    "We can see 20-fold performance increase when switching from laptop to Amazon AWS EC2 c4.8xlarge server, while the numer of cores has increased only 9 times. Thus, we have concluded that the number of cores is not the only factor that helped with the speed-up. We believe that it is full utilization of 20GBit ethernet connection that also played a big role in this 20-fold increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline - 3. Class / Object extraction\n",
    "In this step we will extract all the different classes / objects that were found in our images. We will create list from them in descending order by sum of confidences. This will help us in the following step.\n",
    "\n",
    "To do so we will run [extract_classes.py](https://github.com/korcek-juraj/epfl-ada16-project/blob/master/Instagram-Classification/extract_classes.py) script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load ./extract_classes.py\n",
    "import argparse\n",
    "import json\n",
    "import errno\n",
    "import os\n",
    "\n",
    "\n",
    "def extract_classes(results_filename, classes_filename):\n",
    "    \"\"\"\n",
    "    Reads results JSON file line by line and extracts classes / objects found in every image, i.e., it does groupby by\n",
    "    the class name while aggregating the count for the class and summing over the confidence of the particular class prediction.\n",
    "\n",
    "    The output file is in form of JSON list of tuples (Image ID, {'count': count, 'score': score, 'weight':0}) sorted by\n",
    "    highest score (sum of confidence). Weight stands for sentiment of the particular class. It is set to 0 and is supposed\n",
    "    to be manually changed to values between -1 and 1, before the file can be used for sentiment calculation using\n",
    "    calculate_sentiment.py script.\n",
    "    :param results_filename: filename of the results JSON file to extract classes from\n",
    "    :param classes_filename: filename of a JSON file where the extracted classes will be written\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    classes_dict = {}\n",
    "    img_id_cache = set()\n",
    "    with open(results_filename) as results_file:\n",
    "        for line in results_file:\n",
    "            result_dict = json.loads(line)\n",
    "            img_id = next(iter(result_dict))\n",
    "            if img_id not in img_id_cache:\n",
    "                img_id_cache.add(img_id)\n",
    "                for cls, score in result_dict[img_id].items():\n",
    "                    if cls not in classes_dict:\n",
    "                        classes_dict[cls] = {'weight': 0, 'score': 0, 'count': 0}\n",
    "                    classes_dict[cls]['score'] += score\n",
    "                    classes_dict[cls]['count'] += 1\n",
    "\n",
    "    dir_path = os.path.dirname(classes_filename)\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(dir_path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    with open(classes_filename, 'wt') as classes_file:\n",
    "        json.dump(sorted(list(classes_dict.items()), key=lambda x: x[1]['score'], reverse=True), classes_file, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "\n",
    "    print('No. of classses: ' + str(len(classes_dict)))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-r', '--path_to_results_file', type=str, required=True)\n",
    "    parser.add_argument('-c', '--output_classes_file', type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "    extract_classes(args.path_to_results_file, args.output_classes_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to pass it the file obtained in previous step and a path to filename to be created. Again, to run it from shell you need to execute `python3 extract_classes.py -r results/september-october_urls_result.json  -c results/september-october_urls_classes.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of classses: 999\n"
     ]
    }
   ],
   "source": [
    "%run ./extract_classes.py -r results/september-october_urls_result.json  -c results/september-october_urls_classes.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how resulting file looks similar to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[\n",
    "    [\n",
    "        \"alp\",\n",
    "        {\n",
    "            \"count\": 26,\n",
    "            \"score\": 10.534843739587814,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"lakeside, lakeshore\",\n",
    "        {\n",
    "            \"count\": 33,\n",
    "            \"score\": 5.4354036473087035,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"valley, vale\",\n",
    "        {\n",
    "            \"count\": 27,\n",
    "            \"score\": 3.9698514562333003,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"sunglasses, dark glasses, shades\",\n",
    "        {\n",
    "            \"count\": 8,\n",
    "            \"score\": 2.3758638575673103,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"fountain\",\n",
    "        {\n",
    "            \"count\": 4,\n",
    "            \"score\": 1.854876298457384,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"sunglass\",\n",
    "        {\n",
    "            \"count\": 7,\n",
    "            \"score\": 1.7299124635756016,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"stage\",\n",
    "        {\n",
    "            \"count\": 2,\n",
    "            \"score\": 1.5328002572059631,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"cliff, drop, drop-off\",\n",
    "        {\n",
    "            \"count\": 18,\n",
    "            \"score\": 1.527658513165079,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"plate\",\n",
    "        {\n",
    "            \"count\": 2,\n",
    "            \"score\": 1.3660185933113098,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline - 4. Class / Object sentiment assignment\n",
    "We will use this file to set sentiment for particular objects. For example, to mountain, valley, or lakeside classes we will assign positive sentiment (1), while to face or food classes we will assign neutral sentiment (0). Additionally, if there are some negative classes, e.g. thrash or graffiti we can assign negative sentiment (-1). The fact that the file got ordered in previous step will allow us to focus on the most occuring objects / classes. For example, reulting file might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[\n",
    "    [\n",
    "        \"alp\",\n",
    "        {\n",
    "            \"count\": 26,\n",
    "            \"score\": 10.534843739587814,\n",
    "            \"weight\": 1\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"lakeside, lakeshore\",\n",
    "        {\n",
    "            \"count\": 33,\n",
    "            \"score\": 5.4354036473087035,\n",
    "            \"weight\": 1\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"valley, vale\",\n",
    "        {\n",
    "            \"count\": 27,\n",
    "            \"score\": 3.9698514562333003,\n",
    "            \"weight\": 1\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"sunglasses, dark glasses, shades\",\n",
    "        {\n",
    "            \"count\": 8,\n",
    "            \"score\": 2.3758638575673103,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"fountain\",\n",
    "        {\n",
    "            \"count\": 4,\n",
    "            \"score\": 1.854876298457384,\n",
    "            \"weight\": 1\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"sunglass\",\n",
    "        {\n",
    "            \"count\": 7,\n",
    "            \"score\": 1.7299124635756016,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"stage\",\n",
    "        {\n",
    "            \"count\": 2,\n",
    "            \"score\": 1.5328002572059631,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"cliff, drop, drop-off\",\n",
    "        {\n",
    "            \"count\": 18,\n",
    "            \"score\": 1.527658513165079,\n",
    "            \"weight\": 1\n",
    "        }\n",
    "    ],\n",
    "    [\n",
    "        \"plate\",\n",
    "        {\n",
    "            \"count\": 2,\n",
    "            \"score\": 1.3660185933113098,\n",
    "            \"weight\": 0\n",
    "        }\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline - 5. Sentiment calculation\n",
    "Finally, we will calculate sentiment using results file from step 2 and the classes file from step 4. \n",
    "\n",
    "Basically, the final sentiment of an image is computed by multiplying the confidence of each of 5 objects found in the image (this information is in results file) by the sentiment of given object defined in classes file. Then we sum the results of these 5 products and get final sentiment as a decimal. Additionally, we also compute discrete sentiment from {-1, 0 , 1} using following approach:  \n",
    "    -1 if decimal sentiment is from [-1, -0.33>  \n",
    "     0 if decimal sentiment is from [-0.33, 0.33]  \n",
    "     1 if decimal sentiment is from <0.33, 1]  \n",
    "     \n",
    "This is done by script [calculate_sentiment.py](https://github.com/korcek-juraj/epfl-ada16-project/blob/master/Instagram-Classification/calculate_sentiment.py). The resulting sentiment file is in form of JSON dictionary with Instagram Image IDs as keys and dictionaries with decimal and integer sentiment as values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ./calculate_sentiment.py\n",
    "import argparse\n",
    "import json\n",
    "import errno\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def calculate_sentiment(results_filename, classes_filename, sentiment_filename):\n",
    "    \"\"\"\n",
    "    For every Image ID, it computes sentiment by multiplying confidence/score of classes/objects found in an image corresponding\n",
    "    to the given Image ID from results JSON file (passed in parameter results_filename) with sentiment weight for particular\n",
    "    class defined in classes JSON file (passed in classes_filename parameter) and summing over these products.\n",
    "\n",
    "    The output file is in form of JSON dictionary with Image IDs being keys and dictionaries {'sent_float': float, 'sent_int': int from {-1, 0, 1}}\n",
    "    being values. 'sent_int' is just 'sent_float' discretized into 3 bins:\n",
    "    -1 if 'sent_float' from [-1, -0.33>\n",
    "     0 if 'sent_float' from [-0.33, 0.33]\n",
    "     1 if 'sent_float' from <0.33, 1]\n",
    "    :param results_filename: filename of the results JSON file\n",
    "    :param classes_filename: filename of the JSON file extracted with extract_classes.py script and manually changed to fit the task\n",
    "    :param sentiment_filename: filename of an output JSON file containing dictionary of Instagram Image IDs and their sentiment\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    sentiment_dict = {}\n",
    "\n",
    "    with open(classes_filename) as classes_file:\n",
    "        classes_list = json.load(classes_file)\n",
    "        classes_dict = {cls: attr_dict['weight'] for cls, attr_dict in classes_list}\n",
    "\n",
    "    with open(results_filename) as results_file:\n",
    "        for line in results_file:\n",
    "            result_dict = json.loads(line)\n",
    "            img_id = next(iter(result_dict))\n",
    "            if img_id not in sentiment_dict:\n",
    "                sentiment_dict[img_id] = {'sent_int': 0, 'sent_float': 0}\n",
    "                for cls, score in result_dict[img_id].items():\n",
    "                    sentiment_dict[img_id]['sent_float'] += score * classes_dict[cls]\n",
    "                sentiment_dict[img_id]['sent_int'] = (1 if abs(sentiment_dict[img_id]['sent_float']) > 0.33 else 0) * np.sign(sentiment_dict[img_id]['sent_float'])\n",
    "\n",
    "    dir_path = os.path.dirname(sentiment_filename)\n",
    "    try:\n",
    "        os.makedirs(dir_path)\n",
    "    except OSError as exc: # Python >2.5\n",
    "        if exc.errno == errno.EEXIST and os.path.isdir(dir_path):\n",
    "            pass\n",
    "        else:\n",
    "            raise\n",
    "    with open(sentiment_filename, 'wt') as sentiment_file:\n",
    "        json.dump(sentiment_dict, sentiment_file, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-r', '--path_to_results_file', type=str, required=True)\n",
    "    parser.add_argument('-c', '--path_to_classes_file', type=str, required=True)\n",
    "    parser.add_argument('-o', '--output_sentiment_file', type=str, required=True)\n",
    "    args = parser.parse_args()\n",
    "    calculate_sentiment(args.path_to_results_file, args.path_to_classes_file, args.output_sentiment_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will run the script on the files obtained in steps 2 and 4 to get final sentiments. If you are in shell run `python3 calculate_sentiment.py -r results/september-october_urls_result.json -c results/september-october_urls_classes.json -o results/september-october_urls_sentiment.json` instead of following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%run ./calculate_sentiment.py -r results/september-october_urls_result.json -c results/september-october_urls_classes.json -o results/september-october_urls_sentiment.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resulting results/september-october_urls_sentiment.json sentiment file should look similar to this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "{\n",
    "    \"BJ-YG36jyVm\": {\n",
    "        \"sent_float\": 0.0,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ04ACTAymo\": {\n",
    "        \"sent_float\": 0.613392760977149,\n",
    "        \"sent_int\": 1.0\n",
    "    },\n",
    "    \"BJ05hBchWmP\": {\n",
    "        \"sent_float\": 0.0,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ0Pc3CBq5H\": {\n",
    "        \"sent_float\": 0.5774869928136468,\n",
    "        \"sent_int\": 1.0\n",
    "    },\n",
    "    \"BJ0Zf51BapC\": {\n",
    "        \"sent_float\": 0.0,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ0amnNhpCu\": {\n",
    "        \"sent_float\": 0.8761984705924988,\n",
    "        \"sent_int\": 1.0\n",
    "    },\n",
    "    \"BJ0o9YtBgf4\": {\n",
    "        \"sent_float\": 0.30901558231562376,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ0yLsrg1K-\": {\n",
    "        \"sent_float\": 0.0,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ1AUYmjyZj\": {\n",
    "        \"sent_float\": 0.9857816100120544,\n",
    "        \"sent_int\": 1.0\n",
    "    },\n",
    "    \"BJ1bUPfAnB_\": {\n",
    "        \"sent_float\": 0.0,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ2Je6BjwQE\": {\n",
    "        \"sent_float\": 0.0,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ2JujdA8QL\": {\n",
    "        \"sent_float\": 0.0,\n",
    "        \"sent_int\": 0.0\n",
    "    },\n",
    "    \"BJ2OQ2SBE_C\": {\n",
    "        \"sent_float\": 0.8790866502095014,\n",
    "        \"sent_int\": 1.0\n",
    "    },\n",
    "    \"BJ2tSflAgbZ\": {\n",
    "        \"sent_float\": 0.13510681688785553,\n",
    "        \"sent_int\": 0.0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "The next step would be vizualization of sentiment throughout the Switzerland. For more details on that look into [/GeoVis/](https://github.com/korcek-juraj/epfl-ada16-project/tree/master/GeoVis) folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful bash commands\n",
    "`ssh -i amazonPublicKey.pem ec2-user@ec2-34-249-163-22.eu-west-1.compute.amazonaws.com`  \n",
    "`scp -i amazonPublicKey.pem  pipeline.py ec2-user@ec2-34-249-163-22.eu-west-1.compute.amazonaws.com:~/.`  \n",
    "`less +F filename`  \n",
    "`wc -l filename`  \n",
    "`ps aux | grep python3`  \n",
    "`pkill -f python3`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugesstions for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 64bit",
   "language": "python",
   "name": "python35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
